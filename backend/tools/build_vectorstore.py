# backend/tools/build_vectorstore.py
import os, glob
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

PDF_DIR = os.path.join(os.path.dirname(__file__), "..", "pdfs_madrid")
OUT_DIR = os.path.join(os.path.dirname(__file__), "..", "vectorstore_cache")
os.makedirs(OUT_DIR, exist_ok=True)

print(f"ðŸ“š Leyendo PDFs de: {os.path.abspath(PDF_DIR)}")
pdfs = sorted(glob.glob(os.path.join(PDF_DIR, "*.pdf")))
if not pdfs:
    raise SystemExit("No se encontraron PDFs. Verifica la carpeta 'backend/pdfs_madrid'.")

docs = []
for pdf in pdfs:
    print(f"  - {os.path.basename(pdf)}")
    for d in PyPDFLoader(pdf).load():
        docs.append(d)

print(f"ðŸ§© {len(docs)} documentos. Dividiendo en chunks...")
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
chunks = splitter.split_documents(docs)
print(f"ðŸ§© {len(chunks)} chunks generados.")

print("ðŸ”¢ Creando embeddings (Sentence-Transformers)...")
emb = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

print("ðŸ§  Construyendo Ã­ndice FAISS...")
vs = FAISS.from_documents(chunks, emb)

print(f"ðŸ’¾ Guardando Ã­ndice en: {os.path.abspath(OUT_DIR)}")
vs.save_local(OUT_DIR)

print("âœ… Â¡Vectorstore cache creada! (index.faiss + index.pkl)")
